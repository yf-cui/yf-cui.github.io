# jemdoc: menu{MENU}{index.html}, nofooter
= Yufei Cui

~~~
{}{img_left}{IMG_2900.jpg}{alt text}{203}{278}
Yufei Cui, Postdoc,\n 
[https://www.cs.mcgill.ca School of Computer Science], \n[https://www.mcgill.ca McGill University]\n
~~~

== About
I'm working as a postdoc in McGill University, advised by [https://www.cs.mcgill.ca/~xueliu/site/intro.html, Prof. Xue Liu]. I also lead the AI research lab in [https://www.ibingli.cn/ Bingli Tech], Guangzhou.

I worked as a postdoc from July, 2021 to June 2022, in [https://mlab.hk MLab], CityU HK. Prior to that, I obtained my PhD degree in CityU HK, advised by [https://www.cs.cityu.edu.hk/~jasonxue/ Prof. Chun Jason Xue], [https://www.cs.cityu.edu.hk/~abchan/ Prof. Antoni B. Chan] and [https://www.csie.ntu.edu.tw/~ktw/ Prof. Ted-Wei Kuo]. I obtained MS degree in Telecommunications in HKUST and BE in Communication Engineering in Shandong University.

My research interests include 
. Probabilistic deep learning with applications in:
	.. Medical images and Histopathology.
	.. Light-weight neural network and embedded AI.
	.. Data engineering - data compression and learned index.
. Storage - optimization for flash reliability.


== News

Our paper "Accelerating General-purpose Lossless Compression via Simple and Scalable Parameterization" was accepted in ACM MM 2022.\n/Explicitly modeling local dependency of symbols using variants of [https://arxiv.org/pdf/2101.11353.pdf Variational Nested Dropout] helps build an efficient data compressor./

Our preprint "Variational Nested Dropout" is available on arXiv and is under review as a journal paper. ([https://arxiv.org/pdf/2101.11353.pdf Preprint], [https://github.com/ralphc1212/PyTorch-VAE/tree/vnd_vae Code])\n/A new formulation of variational autoencoder with the ordered latent space is provided./

Our paper "NFL: Robust Learned Index via Distribution Transformation" was accepted in VLDB 2022. ([https://arxiv.org/abs/2205.11807 Preprint], [https://github.com/luffy06/NFL Code])\n/Transforming the distribution of keys with normalizing flow helps build an efficient learned index./

Our paper "A Fast Transformer-based General-Purpose Lossless Compressor" was accepted in TheWebConf 2022. ([https://dl.acm.org/doi/abs/10.1145/3485447.3511987 Paper], [https://github.com/mynotwo/A-Fast-Transformer-based-General-Purpose-LosslessCompressor Code]).

Our paper "CacheSifter: Sifting Cache Files for Boosted Mobile Performance and Lifetime" was accepted in FAST 2022. ([https://www.usenix.org/conference/fast22/presentation/liang Paper])

Serving as reviewer for CVPR-22, NeurIPS-22, ICML-22.

Our paper "Online Rare Category Identification and Data Diversification for Edge Computing" was accepted in TCAD. ([https://ieeexplore.ieee.org/document/9440539 Paper])

Code for "Bayesian Nested Neural Networks for Uncertainty Calibration and Adaptive Compression" using proposed variational nested dropout are released. ([https://github.com/ralphc1212/variational_nested_dropout Code])

Our paper "FlashEmbedding: Storing embedding tables in SSD for large-scale recommender systems" was accepted in APSys 2021. ([https://www.cs.cityu.edu.hk/~huwan2/files/apsys21_wan.pdf Paper])

Our paper "Improve Generalization and Robustness of Neural Networks via Weight Scale Shifting Invariant Regularizations" was accepted in ICML Workshop on Adversarial Machine Learning 2021. ([https://arxiv.org/pdf/2008.02965.pdf Paper])

Our paper "Bayesian Nested Neural Networks for Uncertainty Calibration and Adaptive Compression" was accepted in CVPR 2021. ([https://openaccess.thecvf.com/content/CVPR2021/papers/Cui_Bayesian_Nested_Neural_Networks_for_Uncertainty_Calibration_and_Adaptive_Compression_CVPR_2021_paper.pdf Paper], [https://github.com/ralphc1212/variational_nested_dropout Code])
